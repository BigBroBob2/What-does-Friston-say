## G-Density: how brain encodes beliefs about world causes

Approximation of VFE, the so-called Laplace-encoded energy $E(\mu,\varphi)$ is over approximate G-density $p(\mu,\varphi)$, which replaces world states $\vartheta$ with sufficient statistical mean $\mu$.

Here we build generative models of world causal dependencies in world and relation to sensory data. Then from generative models we derive specification of G-density.

### The simplest generative model

Definition table

|Symbol|Name \& Description|
|:-|:-|
|$g(\mu;\vartheta)$         |generative mapping     |
|$z$                        |Guassian noise, $N(0,\sigma_z)$       |
|$w$                        |Guassian noise, $N(0,\sigma_w)$       |
|$p(\varphi \mid \mu)$      |likelihood of $\mu$, implicit beliefs about how agent belief about world state $\mu$ map to sensory input $\varphi$|
|$p(\mu)$                   |*prior* of $\mu$, before sensory input $\varphi$|

Simplest model:
- single world state $\vartheta$ and single sensory channel
- agent uses single brain state $\mu$ and sensory input $\varphi$

Agent has generative belief of sensory input $\varphi$:

$\varphi = g(\mu;\vartheta)+z$

Where $g$ is a function and $z$ is zero-mean white noise. This means agent believes a mapping from world state (here denoted as its belief about world state $\mu$) to sensory input.

Assume the agent belief about world state is generated by:

$\mu = \bar{\mu}+w$

Where $\bar{\mu}$ is fixed parameter and $w$ is zero-mean white noise. This means agent takes belief of world states history-independently, fluctuating around $\bar{\mu}$ as *priori*. 

Note that $\mu$ itself represents mean value of world state $\vartheta$, although generated from a distribution. There is a conflict that the best estimated $\mu$, which is $q(\vartheta)$-average $\int \vartheta q(\vartheta) d\vartheta$, may not necessarily be the same as the world model expectation $\bar{\mu}$. 

Given the Guassian distribution of $z$:

$p(z) = \frac{1}{\sqrt{2\pi\sigma_z}} \exp \left ( - \frac{z^2}{2\sigma_z}\right )$

Substitute $z=\varphi-g(\mu;\vartheta)$ and we get $p(\varphi|\mu)$:

$p(\varphi|\mu) = \frac{1}{\sqrt{2\pi\sigma_z}} \exp \left ( - \frac{(\varphi-g(\mu;\vartheta))^2}{2\sigma_z}\right )$

Also we have $p(\mu)$:

$p(\mu) = \frac{1}{\sqrt{2\pi\sigma_w}} \exp \left ( - \frac{(\mu-\bar{\mu})^2}{2\sigma_w}\right )$

The Laplace-encoded G-density $p(\mu,\varphi)$:

$p(\mu,\varphi) = p(\varphi \mid \mu)p(\mu)$

The Laplace-encoded energy $E(\mu,\varphi)$:

$E(\mu,\varphi) = - \ln p(\varphi \mid \mu) - \ln p(\mu) = \frac{1}{2\sigma_z} (\varphi-g(\mu;\vartheta))^2+ \frac{1}{2\sigma_w} (\mu-\bar{\mu})^2 + \frac{1}{2} \ln (\sigma_z \sigma_w) \equiv \frac{1}{2}\sigma_z \varepsilon_z^2+ \frac{1}{2}\sigma_w \varepsilon_w^2 + \frac{1}{2} \ln (\sigma_z \sigma_w)$

Where in predictive coding terminology:
- $\varepsilon_z = \frac{\mu-\bar{\mu}}{\sigma_z}$ is called **residual error**, sensory prediction error;
- $\varepsilon_w = \frac{\varphi-g(\mu;\vartheta)}{\sigma_w}$ is called **prediction error**, model prediction error;
- Both errors have weighted coefficients, how they contribute to the Laplace-encoded energy.

Extend from univariate to multivariate case. For vector of $N$ brain states $\{\mu_\alpha\}$:

$\mu_\alpha = \bar{\mu}_\alpha+w_\alpha$

Note that here noise sources $\{w_\alpha\}$ may be correlated and not independent:

$\vec{w} \sim N \left ( \vec{0},\Sigma_w \right )$

The vector of $N$ snesory inputs $\{\varphi_\alpha\}$:

$\varphi_\alpha = g_\alpha (\mu_0,\dots, \mu_N) + z_\alpha$

Here noise sources $\{w_z\}$ may be correlated and not independent:

$\vec{z} \sim N \left ( \vec{0},\Sigma_z \right )$

The *prior* of brain states:

$p(\vec{\mu}) = \frac{1}{\sqrt{(2\pi)^N | \Sigma_w |}} \exp \left ( -\frac{1}{2}(\vec{\mu}-\vec{\bar{\mu}})^T \Sigma_w^{-1} (\vec{\mu}-\vec{\bar{\mu}}) \right )$

The likelihood density:

$p(\vec{\varphi} \mid \vec{\mu}) = \frac{1}{\sqrt{(2\pi)^N | \Sigma_z |}} \exp \left ( -\frac{1}{2}(\vec{\varphi}-g(\vec{\mu}))^T \Sigma_z^{-1} (\vec{\varphi}-g(\vec{\mu})) \right )$

The Laplace-encoded energy:

$E(\mu,\varphi) = \frac{1}{2} (\vec{\mu}-\vec{\bar{\mu}})^T \Sigma_w^{-1} (\vec{\mu}-\vec{\bar{\mu}}) + \frac{1}{2} (\vec{\varphi}-g(\vec{\mu}))^T \Sigma_z^{-1} (\vec{\varphi}-g(\vec{\mu})) + \frac{1}{2} \ln | \Sigma_z | +  \frac{1}{2} \ln | \Sigma_w |$

Where in predictive coding terminology:
- $\vec{\varepsilon}_z = \Sigma_w^{-1} (\vec{\mu}-\vec{\bar{\mu}})$ is called **residual error**, sensory prediction error;
- $\vec{\varepsilon}_w = \Sigma_z^{-1} (\vec{\varphi}-g(\vec{\mu}))$ is called **prediction error**, model prediction error.

### Dynamical generative model

Definition table

|Symbol|Name \& Description|
|:-|:-|
|$\tilde{\mu}$            |a univariate brain state in generalised coordinates|
|$\tilde{\varphi}$        |a univariate sensory input in generalised coordinates|
|$\tilde{g}$              |generative mapping from $\tilde{\mu}$ to $\tilde{\varphi}$ in generalised coordinates|
|$\tilde{f}$              |generative equation of motion of agent belief about world state, from $\tilde{\varphi}$ to $D\tilde{\mu}$ in generalised coordinates|
|$p(\tilde{\varphi} \mid \tilde{\mu})$      |likelihood of $\tilde{\mu}$, implicit beliefs about how agent belief about world state $\tilde{\mu}$ map to sensory input $\tilde{\varphi}$|
|$p(\tilde{\mu})$                   |*prior* of $\tilde{\mu}$, before sensory input $\tilde{\varphi}$|

Simplest dynamical model:
- agent uses single brain state $\mu$ and sensory input $\varphi$

Assume the agent belief $\mu$ about world state is generated by:

$\frac{d\mu}{dt} = f(\mu)+w$

Agent has generative belief of sensory input $\varphi$:

$\varphi = g(\mu;\vartheta)+z$


Generalised coordinates \& Higher-order motion
- representing dynamical system states in increasingly higher order derivative of its state variables
- For sensory data $\varphi$:
  - recursively higher order derivatives in form of $\varphi^{(n)} = \frac{\partial g}{\partial \mu} \mu^{(n)} + z^{(n)}$
    - note that $\{z^{(n)}\}$ are noise sources at each dynamic order and may be correlated
    - non-linear terms like ${\mu^{(n)}}^2$ and $\mu^{(n)}\mu^{(m)}$ are neglected under **local linear assumption**
  - denote
    - $\tilde{\varphi} = (\varphi^{(0)},\varphi^{(1)},\dots)^T \equiv (\varphi_{[0]},\varphi_{[1]},\dots)^T$
    - $\tilde{z} = (z^{(0)},z^{(1)},\dots)^T \equiv (z_{[0]},z_{[1]},\dots)^T$
    - $\tilde{g} = (g(\mu),\frac{\partial g}{\partial \mu} \mu_{[1]},\dots)^T \equiv (g_{[0]},g_{[1]},\dots)^T$
- For the agent belief about world state $\mu$:
  - recursively higher order derivatives in form of $\mu^{(n+1)} = \frac{\partial f}{\partial \mu} \mu^{(n)} + w^{(n)}$
    -  note that $\{w^{(n)}\}$ are noise sources at each dynamic order and may be correlated
    - non-linear terms are neglected under **local linear assumption**
  - denote
    - $\tilde{\mu} = (\mu^{(0)},\mu^{(1)},\dots)^T \equiv (\mu_{[0]},\mu_{[1]},\dots)^T$
    - $\tilde{w} = (w^{(0)},w^{(1)},\dots)^T \equiv (w_{[0]},w_{[1]},\dots)^T$
    - $\tilde{f} = (f(\mu),\frac{\partial f}{\partial \mu} \mu_{[1]},\dots)^T \equiv (f_{[0]},f_{[1]},\dots)^T$

Therefore we can write in compact form:

$\tilde{\varphi} = \tilde{g}+\tilde{z}$

$D\tilde{\mu} = \tilde{f}+\tilde{w}$

Where $D$ means shift one towards higher order, $\tilde{z}$ and $\tilde{w}$ follow Guassian distribution:

$\tilde{z} \sim N(\vec{0},\Sigma_z)$

$\tilde{w} \sim N(\vec{0},\Sigma_w)$

Then we calculate the likelihood of sensory data $p(\tilde{\varphi} \mid \tilde{\mu})$:

$p(\tilde{\varphi} \mid \tilde{\mu}) = \frac{1}{\sqrt{(2\pi)^{n_{\rm max}+1} | \Sigma_z |}} \exp \left ( -\frac{1}{2}(\tilde{\varphi}-\tilde{g})^T \Sigma_z^{-1} (\tilde{\varphi}-\tilde{g}) \right )$

And the *prior* of agent belief about world state $p(\tilde{\mu})$:

$p(\tilde{\mu}) = \frac{1}{\sqrt{(2\pi)^{n_{\rm max}+1} | \Sigma_w |}} \exp \left ( -\frac{1}{2}(D\tilde{\mu}-\tilde{f})^T \Sigma_w^{-1} (D\tilde{\mu}-\tilde{f}) \right )$

The Laplace-encoded energy:

$E(\mu,\varphi) = \frac{1}{2} (D\tilde{\mu}-\tilde{f})^T \Sigma_w^{-1} (D\tilde{\mu}-\tilde{f}) + \frac{1}{2} (\tilde{\varphi}-\tilde{g})^T \Sigma_z^{-1} (\tilde{\varphi}-\tilde{g}) + \frac{1}{2} \ln | \Sigma_z | +  \frac{1}{2} \ln | \Sigma_w |$

Similarly we can define errors in predictive coding terminology:
- $\tilde{\varepsilon}_z = \Sigma_w^{-1} (D\tilde{\mu}-\tilde{f})$ is called **residual error**, sensory prediction error;
- $\vec{\varepsilon}_w = \Sigma_z^{-1} (\tilde{\varphi}-\tilde{g})$ is called **prediction error**, model prediction error.

Consider dynamics up to finite order $n_{\rm max}$, this can be done by setting the highest order term to random fluctuation with large variance:

$\mu_{[n_{\rm max}]} = w_{[n_{\rm max}]}$

Then orders higher than $n_{\rm max}$ will be close to zero and ignored, only orders lower than $n_{\rm max}$ are considered.

Extend from univariate to multivariate case:
- agent uses vectors of brain state $\{\tilde{\mu}_\alpha\}$ and sensory input $\{\tilde{\varphi}_\alpha\}$
- For simplisity, consider independent $\{\tilde{\mu}_\alpha\}$ and $\{\tilde{\varphi}_\alpha\}$; otherwise we should consider correlation between dynamic orders and different varibles "$n \times \alpha$"

We have:

$\tilde{\varphi}_\alpha = \tilde{g}_\alpha+\tilde{z}_\alpha$

$D\tilde{\mu}_\alpha = \tilde{f}_\alpha+\tilde{w}_\alpha$

The Laplace-encoded energy:

$E(\{\tilde{\mu}_\alpha\},\{\tilde{\varphi}_\alpha\}) = \sum_{\alpha = 1}^{N} \left ( \frac{1}{2} (D\tilde{\mu}_\alpha-\tilde{f}_\alpha)^T \Sigma_{w_\alpha}^{-1} (D\tilde{\mu}_\alpha-\tilde{f}_\alpha) + \frac{1}{2} (\tilde{\varphi}_\alpha-\tilde{g}_\alpha)^T \Sigma_{z_\alpha}^{-1} (\tilde{\varphi}_\alpha-\tilde{g}_\alpha) + \frac{1}{2} \ln | \Sigma_{z_\alpha} | +  \frac{1}{2} \ln | \Sigma_{w_\alpha} | \right )$
